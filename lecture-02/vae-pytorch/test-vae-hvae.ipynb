{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80135c87-8373-44a9-b2de-f19bc0e06a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VanillaVAE\n",
    "from models import HVAE\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f95391-d43b-46d2-a5b3-ad6508165a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vanilla_vae():\n",
    "    # Decide on device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_str = \"cuda\" if device.type == \"cuda\" else \"cpu\"\n",
    "\n",
    "    # Instantiate model and move to device\n",
    "    model = VanillaVAE(3, 10).to(device)\n",
    "\n",
    "    print(\"=== Model Summary ===\")\n",
    "    # Tell summary which device to use\n",
    "    print(summary(model, input_size=(1, 3, 64, 64), device=device_str))\n",
    "\n",
    "    # Forward pass test\n",
    "    print(\"\\n=== Forward Test ===\")\n",
    "    x = torch.randn(16, 3, 64, 64, device=device)\n",
    "    out = model(x)\n",
    "    print(\"Output[0] shape:\", out[0].shape)\n",
    "\n",
    "    # Loss test\n",
    "    print(\"\\n=== Loss Test ===\")\n",
    "    loss = model.loss_function(*out, M_N=0.005)\n",
    "    print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b006986b-7705-4d40-9681-0bdeceb65c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hvae():\n",
    "\n",
    "    # Decide on device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_str = \"cuda\" if device.type == \"cuda\" else \"cpu\"\n",
    "\n",
    "    # Instantiate model and move to device\n",
    "    model = HVAE(3, latent1_dim=10, latent2_dim=20).to(device)\n",
    "\n",
    "    print(\"=== Model Summary ===\")\n",
    "    # Tell summary which device to use\n",
    "    print(summary(model, input_size=(1, 3, 64, 64), device=device_str))\n",
    "\n",
    "    # Forward pass test\n",
    "    print(\"\\n=== Forward Test ===\")\n",
    "    x = torch.randn(16, 3, 64, 64, device=device)\n",
    "    out = model(x)\n",
    "    print(\"Output[0] shape:\", out[0].shape)\n",
    "\n",
    "    # Loss test\n",
    "    print(\"\\n=== Loss Test ===\")\n",
    "    loss = model.loss_function(*out, M_N=0.005)\n",
    "    print(\"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8b82f7-8f6f-4f2e-bab3-c2a3eb831a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "VanillaVAE                               [1, 3, 64, 64]            --\n",
      "├─Sequential: 1-1                        [1, 512, 2, 2]            --\n",
      "│    └─Sequential: 2-1                   [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 32, 32, 32]           896\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-3               [1, 32, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-4                  [1, 64, 16, 16]           18,496\n",
      "│    │    └─BatchNorm2d: 3-5             [1, 64, 16, 16]           128\n",
      "│    │    └─LeakyReLU: 3-6               [1, 64, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-7                  [1, 128, 8, 8]            73,856\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 128, 8, 8]            256\n",
      "│    │    └─LeakyReLU: 3-9               [1, 128, 8, 8]            --\n",
      "│    └─Sequential: 2-4                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-10                 [1, 256, 4, 4]            295,168\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 256, 4, 4]            512\n",
      "│    │    └─LeakyReLU: 3-12              [1, 256, 4, 4]            --\n",
      "│    └─Sequential: 2-5                   [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-13                 [1, 512, 2, 2]            1,180,160\n",
      "│    │    └─BatchNorm2d: 3-14            [1, 512, 2, 2]            1,024\n",
      "│    │    └─LeakyReLU: 3-15              [1, 512, 2, 2]            --\n",
      "├─Linear: 1-2                            [1, 10]                   20,490\n",
      "├─Linear: 1-3                            [1, 10]                   20,490\n",
      "├─Linear: 1-4                            [1, 2048]                 22,528\n",
      "├─Sequential: 1-5                        [1, 32, 32, 32]           --\n",
      "│    └─Sequential: 2-6                   [1, 256, 4, 4]            --\n",
      "│    │    └─ConvTranspose2d: 3-16        [1, 256, 4, 4]            1,179,904\n",
      "│    │    └─BatchNorm2d: 3-17            [1, 256, 4, 4]            512\n",
      "│    │    └─LeakyReLU: 3-18              [1, 256, 4, 4]            --\n",
      "│    └─Sequential: 2-7                   [1, 128, 8, 8]            --\n",
      "│    │    └─ConvTranspose2d: 3-19        [1, 128, 8, 8]            295,040\n",
      "│    │    └─BatchNorm2d: 3-20            [1, 128, 8, 8]            256\n",
      "│    │    └─LeakyReLU: 3-21              [1, 128, 8, 8]            --\n",
      "│    └─Sequential: 2-8                   [1, 64, 16, 16]           --\n",
      "│    │    └─ConvTranspose2d: 3-22        [1, 64, 16, 16]           73,792\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 64, 16, 16]           128\n",
      "│    │    └─LeakyReLU: 3-24              [1, 64, 16, 16]           --\n",
      "│    └─Sequential: 2-9                   [1, 32, 32, 32]           --\n",
      "│    │    └─ConvTranspose2d: 3-25        [1, 32, 32, 32]           18,464\n",
      "│    │    └─BatchNorm2d: 3-26            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-27              [1, 32, 32, 32]           --\n",
      "├─Sequential: 1-6                        [1, 3, 64, 64]            --\n",
      "│    └─ConvTranspose2d: 2-10             [1, 32, 64, 64]           9,248\n",
      "│    └─BatchNorm2d: 2-11                 [1, 32, 64, 64]           64\n",
      "│    └─LeakyReLU: 2-12                   [1, 32, 64, 64]           --\n",
      "│    └─Conv2d: 2-13                      [1, 3, 64, 64]            867\n",
      "│    └─Tanh: 2-14                        [1, 3, 64, 64]            --\n",
      "==========================================================================================\n",
      "Total params: 3,212,407\n",
      "Trainable params: 3,212,407\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 136.88\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 4.21\n",
      "Params size (MB): 12.85\n",
      "Estimated Total Size (MB): 17.11\n",
      "==========================================================================================\n",
      "\n",
      "=== Forward Test ===\n",
      "Output[0] shape: torch.Size([16, 3, 64, 64])\n",
      "\n",
      "=== Loss Test ===\n",
      "Loss: {'loss': tensor(1.1316, device='cuda:0', grad_fn=<AddBackward0>), 'Reconstruction_Loss': tensor(1.1244, device='cuda:0'), 'KLD': tensor(-1.4520, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "test_vanilla_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccec0d4e-7fff-44b8-aa59-7f022aeb08e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Summary ===\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "HVAE                                     [1, 3, 64, 64]            420\n",
      "├─Sequential: 1-1                        [1, 512, 2, 2]            --\n",
      "│    └─Sequential: 2-1                   [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 32, 32, 32]           896\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-3               [1, 32, 32, 32]           --\n",
      "│    └─Sequential: 2-2                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-4                  [1, 64, 16, 16]           18,496\n",
      "│    │    └─BatchNorm2d: 3-5             [1, 64, 16, 16]           128\n",
      "│    │    └─LeakyReLU: 3-6               [1, 64, 16, 16]           --\n",
      "│    └─Sequential: 2-3                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-7                  [1, 128, 8, 8]            73,856\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 128, 8, 8]            256\n",
      "│    │    └─LeakyReLU: 3-9               [1, 128, 8, 8]            --\n",
      "│    └─Sequential: 2-4                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-10                 [1, 256, 4, 4]            295,168\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 256, 4, 4]            512\n",
      "│    │    └─LeakyReLU: 3-12              [1, 256, 4, 4]            --\n",
      "│    └─Sequential: 2-5                   [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-13                 [1, 512, 2, 2]            1,180,160\n",
      "│    │    └─BatchNorm2d: 3-14            [1, 512, 2, 2]            1,024\n",
      "│    │    └─LeakyReLU: 3-15              [1, 512, 2, 2]            --\n",
      "├─Linear: 1-2                            [1, 20]                   40,980\n",
      "├─Linear: 1-3                            [1, 20]                   40,980\n",
      "├─Conv2d: 1-4                            [1, 3, 64, 64]            12\n",
      "├─Linear: 1-5                            [1, 4096]                 86,016\n",
      "├─Sequential: 1-6                        [1, 512, 2, 2]            --\n",
      "│    └─Sequential: 2-6                   [1, 32, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-16                 [1, 32, 32, 32]           1,184\n",
      "│    │    └─BatchNorm2d: 3-17            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-18              [1, 32, 32, 32]           --\n",
      "│    └─Sequential: 2-7                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-19                 [1, 64, 16, 16]           18,496\n",
      "│    │    └─BatchNorm2d: 3-20            [1, 64, 16, 16]           128\n",
      "│    │    └─LeakyReLU: 3-21              [1, 64, 16, 16]           --\n",
      "│    └─Sequential: 2-8                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-22                 [1, 128, 8, 8]            73,856\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 128, 8, 8]            256\n",
      "│    │    └─LeakyReLU: 3-24              [1, 128, 8, 8]            --\n",
      "│    └─Sequential: 2-9                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-25                 [1, 256, 4, 4]            295,168\n",
      "│    │    └─BatchNorm2d: 3-26            [1, 256, 4, 4]            512\n",
      "│    │    └─LeakyReLU: 3-27              [1, 256, 4, 4]            --\n",
      "│    └─Sequential: 2-10                  [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-28                 [1, 512, 2, 2]            1,180,160\n",
      "│    │    └─BatchNorm2d: 3-29            [1, 512, 2, 2]            1,024\n",
      "│    │    └─LeakyReLU: 3-30              [1, 512, 2, 2]            --\n",
      "├─Linear: 1-7                            [1, 10]                   20,490\n",
      "├─Linear: 1-8                            [1, 10]                   20,490\n",
      "├─Linear: 1-9                            [1, 1024]                 11,264\n",
      "├─Linear: 1-10                           [1, 1024]                 21,504\n",
      "├─Sequential: 1-11                       [1, 32, 32, 32]           --\n",
      "│    └─Sequential: 2-11                  [1, 256, 4, 4]            --\n",
      "│    │    └─ConvTranspose2d: 3-31        [1, 256, 4, 4]            1,179,904\n",
      "│    │    └─BatchNorm2d: 3-32            [1, 256, 4, 4]            512\n",
      "│    │    └─LeakyReLU: 3-33              [1, 256, 4, 4]            --\n",
      "│    └─Sequential: 2-12                  [1, 128, 8, 8]            --\n",
      "│    │    └─ConvTranspose2d: 3-34        [1, 128, 8, 8]            295,040\n",
      "│    │    └─BatchNorm2d: 3-35            [1, 128, 8, 8]            256\n",
      "│    │    └─LeakyReLU: 3-36              [1, 128, 8, 8]            --\n",
      "│    └─Sequential: 2-13                  [1, 64, 16, 16]           --\n",
      "│    │    └─ConvTranspose2d: 3-37        [1, 64, 16, 16]           73,792\n",
      "│    │    └─BatchNorm2d: 3-38            [1, 64, 16, 16]           128\n",
      "│    │    └─LeakyReLU: 3-39              [1, 64, 16, 16]           --\n",
      "│    └─Sequential: 2-14                  [1, 32, 32, 32]           --\n",
      "│    │    └─ConvTranspose2d: 3-40        [1, 32, 32, 32]           18,464\n",
      "│    │    └─BatchNorm2d: 3-41            [1, 32, 32, 32]           64\n",
      "│    │    └─LeakyReLU: 3-42              [1, 32, 32, 32]           --\n",
      "├─Sequential: 1-12                       [1, 3, 64, 64]            --\n",
      "│    └─ConvTranspose2d: 2-15             [1, 32, 64, 64]           9,248\n",
      "│    └─BatchNorm2d: 2-16                 [1, 32, 64, 64]           64\n",
      "│    └─LeakyReLU: 2-17                   [1, 32, 64, 64]           --\n",
      "│    └─Conv2d: 2-18                      [1, 3, 64, 64]            867\n",
      "│    └─Tanh: 2-19                        [1, 3, 64, 64]            --\n",
      "==========================================================================================\n",
      "Total params: 4,961,903\n",
      "Trainable params: 4,961,903\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 157.23\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 5.36\n",
      "Params size (MB): 19.85\n",
      "Estimated Total Size (MB): 25.25\n",
      "==========================================================================================\n",
      "\n",
      "=== Forward Test ===\n",
      "Output[0] shape: torch.Size([16, 3, 64, 64])\n",
      "\n",
      "=== Loss Test ===\n",
      "Loss: {'loss': tensor(1.0569, device='cuda:0', grad_fn=<AddBackward0>), 'Reconstruction Loss': tensor(1.0875, device='cuda:0', grad_fn=<MseLossBackward0>), 'KLD': tensor(6.1373, device='cuda:0', grad_fn=<NegBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "test_hvae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f623478c-989a-4d7c-97ec-7813dc154889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed set to 1265\n",
      "Using CUDA with 1 GPU(s): [1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/data/baojian/git/diff-course/lecture-02/codes/run.py\", line 122, in <module>\n",
      "    main()\n",
      "  File \"/mnt/data/baojian/git/diff-course/lecture-02/codes/run.py\", line 86, in main\n",
      "    data.setup()\n",
      "  File \"/mnt/data/baojian/git/diff-course/lecture-02/codes/dataset.py\", line 140, in setup\n",
      "    self.train_dataset = MyCelebA(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/mnt/data/baojian/anaconda3/envs/diff-course/lib/python3.12/site-packages/torchvision/datasets/celeba.py\", line 97, in __init__\n",
      "    splits = self._load_csv(\"list_eval_partition.txt\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/mnt/data/baojian/anaconda3/envs/diff-course/lib/python3.12/site-packages/torchvision/datasets/celeba.py\", line 122, in _load_csv\n",
      "    with open(os.path.join(self.root, self.base_folder, filename)) as csv_file:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '.cache/celeba/list_eval_partition.txt'\n"
     ]
    }
   ],
   "source": [
    "! python run.py -c configs/vae.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
